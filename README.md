# Home_Sales
Sree Module 22 Challenge
* Created Spark session object
* Used Spark object to access the url and get the files.
* Created Temporary view of the dataframe.
* Used sparksql to perform the queries on the data frame.
* Cached the temp table and verified.
* Performed SQL operations on the cached table.
* Partitioned DF by date_build on the formatted parquet home sales data.
* Created Temporary view of the partitioned dataframe.
* Performed SQL operations on the partitioned temp view
* Uncached home_sales table and verified.
